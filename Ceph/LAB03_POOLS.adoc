= LAB03 - Trabalhando com Pools


= LAB03 - Trabalhando com Pools



*O que é Red Hat Ceph Storage Pools ?*

Pools são partições lógicas do cluster do Red Hat Ceph Storage que armazenam objetos. As piscinas têm atributos específicos:

 - O tipo de pool, que determina o mecanismo de proteção que o pool usa para garantir a durabilidade dos dados.
    * O tipo de *replicação* distribui várias cópias de cada objeto no cluster.
    * O tipo *Erasure Coding* divide cada objeto em partes e distribui-as junto com partes codificadas de eliminação adicionais para proteger objetos usando um mecanismo automático de correção de erros.

 - O número de _Placement Groups_ - Grupos de Posicionamento (PGs) no pool, que armazena seus objetos em um conjunto de OSDs determinado pelo algoritmo CRUSH.

 - Um conjunto de regras CRUSH (Replicação Controlada Sob Hashing Escalonável) que o Ceph usa para identificar qual grupo de veiculações deve conter cada objeto que ele armazena.

 - Garantir um nível de acesso para determinar os direitos de acesso para diferentes usuários.


*Detalhes do funcionando do tratamento de um objeto dentro do Pool.*

Quando o Ceph armazena um objeto em um pool, ele atribui o objeto a um dos grupos de posicionamento do pool usando o conjunto de regras CRUSH.
O grupo de veiculações é mapeado automaticamente para um conjunto de OSDs com base na configuração do pool e no algoritmo CRUSH.
Isso determina os OSDs que o Ceph usa para armazenar o objeto. O tipo de pool determina como esse objeto é replicado ou armazenado nos OSDs nesse conjunto.

Um administrador de armazenamento pode configurar o conjunto de regras CRUSH para que o Ceph armazene os objetos usando OSDs que contêm determinados tipos de dispositivos de armazenamento (como SSDs) ou em dispositivos que estejam em diferentes locais físicos.


*Dilema PG*

O número de grupos de veiculações em um pool tem um grande impacto no desempenho. Se você configurar muito poucos grupos de veiculação em um pool, muitos dados precisarão ser armazenados em cada PG e o Ceph não terá um bom desempenho.

Se você configurar muitos grupos de posicionamento em um pool, os OSDs exigirão uma grande quantidade de RAM e tempo de CPU, e o Ceph não terá um bom desempenho.
Normalmente, um pool deve ser configurado para conter de 100 a 200 grupos de veiculações por OSD.



=== Workout do laborátorio03 - Atividades

.Atividades do laboratório03
|===
|Atividade | Objetivos
|01| Criação de um pool replicado
|1.1| Listando detalhes de um pool replicado
|02| Trabalhando de um pool erasure code
|03| Habilitando um pool
|04| Coletando informações sobre um pool
|05| Setando quotas para Pool
|06| Renomeando um pool
|07| Snapshot de um pool
|08| Trablahando com namespace
|09| Removendo um pool
|===


=== Atividade 01: _Criação de um pool replicado_

*Comando:*

    ceph osd pool create pool_bsb  50 50

*Parâmetros utilizados:*

    ceph osd pool create pool-name  pg-num [pgp-num]   [replicated] [crush-ruleset-name] [expected-num-objects]

=== Atividade 02: _Criação de um pool erasure code_

Antes de criar um pool erasure code, vamos entender os perfils disponíveis para criação de um profile erasure-code

*Procedimento para listar profile padrão*:

   ceph osd erasure-code-profile ls
   default

*Pegando detalhes do perfil do profile erasure code*

  ceph osd erasure-code-profile get default
  k=2
  m=1
  plugin=jerasure
  technique=reed_sol_van

*Criando um perfil novo 'ceph125' e com a configuração de tratamento do OSD - crush failure domain para osd*

 ceph osd erasure-code-profile set ceph125 k=3 m=2 \ > crush-failure-domain=osd


*Pegando informação no novo perfil ceph125*

 ceph osd erasure-code-profile get ceph125
 crush-device-class=
 crush-failure-domain=osd
 crush-root=default
 jerasure-per-chunk-alignment=false
 k=3
 m=2
 plugin=jerasure
 technique=reed_sol_van
 w=8


*Criando pool usando novo profile erasure code*

 ceph osd pool create pool_sp 64 64 erasure ceph125
 > pool 'pool_sp' created

=== Atividade 03: _Habilitando um pool_

Um pool pode ser habilitado em pelo menos três tipos de aplicação:

  * cephfs: Aplicação do ceph para filesystem
  * rbd: ceph bloco device
  * rgw: ceph object gateway


*Exemplo do pamrâmetro*

 ceph osd pool application enable pool-name app

*Comando para habilitar aplicação de um pool:*

 ceph osd pool application enable pool_df rbd <1>
 ceph osd pool application enable pool_sp rbw <2>

<1> Habilitamos para o 'pool_df' aplicação rbd
<2> Habilitamos para o 'pool_sp' aplicação rbw


=== Atividade 04: _Coletando informações sobre um pool_

Podemos criar diversos tipos de pool, como foi visto nos exercícios anteriores. Agora como podemos pegar informações sobre o pool já criado ?

*Comando para listar detalhes do tipo do pool*

- Informações: nome do pool, tamanho da réplica, tamanho da réplica mínima, regra rush e detalhes sobre PG

  ceph osd pool ls detail

*Comando para listar informações sobre armazenamento do pool*

  ceph df

*Comando para listar detalhes de desempenho do pool*

  ceph osd pool stats

=== Atividade 05: _Setando quotas para Pool_

Os administradores podem definir cotas para limitar o número máximo de bytes ou o número máximo de objetos que podem ser armazenados no pool. Use o comando set-quota do pool ceph osd para este propósito.
 

*Exemplo de comando para definir quotas*

 ceph osd pool set-quota pool_bsb max_objects 1000

 ceph osd pool set-quota pool_sp max_objects 500

=== Atividade 06: _Renomeando pool_

Você pode renomear um conjunto com o comando renomear pool do cef osd. Isso não afeta os dados armazenados no pool.


*Modelo de comando para renomear um pool*

 ceph osd pool rename current-name new-name

*Exemplo de comando para renomar um pool*

  ceph osd pool rename pool_bsb pool_bh
  ceph osd pool rename pool_sp pool_rio

=== Atividade 07: _Tirando e removendo snapshot de um pool_

Você pode criar e remover snapshot de um pool replicado usando os comandos *mksnap ceph osd pool* e *rmsnap do pool ceph osd*, da seguinte maneira:


* Exemplo de comando para tirar e remover snapshot*

  ceph osd pool mksnap pool_rio snap-pool-rios
  ceph osd pool rmsnap pool_rio snap-pool-rios


=== Atividade 08: Trabalhando com namespace

Para armazenar um objeto dentro de um namespace, o aplicativo cliente deve fornecer o pool e os nomes de namespace.

_Por padrão, cada pool contém um namespace com um nome vazio, conhecido como namespace padrão. Consulte a documentação da API do Ceph para obter instruções sobre como passar os parâmetros pool e namespace em http://docs.ceph.com/docs/luminous/rados/api/librados/._

Nesta atividade iremos adicionar o arquivo */etc/hosts* como objecto *hosts* dentro do pool *pool_rio*  separado pelpo namespace customizado com nome _workshop-bsb_ .

*Exemplo de comando para realização da atividade*

 rados -p pool_rio -N workshop-bsb put hosts /etc/hosts

*Listando o conteudo do namespace*

 rados -p pool_rio -N workshop-bsb ls

*Listando todos os namespaces*

 rados -p pool_rio --all ls

*Listando o conteudo do pool dentro de um arquivo JSON*

 rados -p pool_rio --all ls --format=json | python -m json.tool

 
